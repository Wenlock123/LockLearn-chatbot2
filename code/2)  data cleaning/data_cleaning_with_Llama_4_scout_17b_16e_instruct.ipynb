{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ñ‡∏≥‡πÄ‡πÄ‡∏ô‡∏∞‡∏ô‡∏≥\n",
        "\n",
        "\n",
        "*   ‡πÉ‡∏´‡πâ‡πÑ‡∏õ‡∏Ç‡∏≠‡πÉ‡∏ä‡πâ Api ‡∏Ç‡∏≠‡∏á‡∏ó‡∏≤‡∏á GroqCloud\n",
        "  ‡∏•‡∏¥‡πâ‡∏á‡∏™‡∏°‡∏±‡∏Ñ‡∏£ Api[Groq api](https://console.groq.com)\n",
        "\n",
        "\n",
        "*   ‡πÉ‡∏´‡πâ‡πÑ‡∏õ‡∏Ç‡∏≠‡πÉ‡∏ä‡πâ Api ‡∏Ç‡∏≠‡∏á‡∏ó‡∏≤‡∏á together ai  \n",
        "  ‡∏•‡∏¥‡πâ‡∏á‡∏™‡∏°‡∏±‡∏Ñ‡∏£[together ai ](https://api.together.ai)\n",
        "\n",
        "\n",
        "*   ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° google drive\n",
        "\n"
      ],
      "metadata": {
        "id": "ia5DDbIN5Awu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ clean ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ OCR ‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLM ‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢  ( Llama-4-scout-17b-16e-instruct)**"
      ],
      "metadata": {
        "id": "uzmmDsBX5k86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° google drive"
      ],
      "metadata": {
        "id": "JqLhNzMo4-YF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOy2unNK4zne"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏ä‡πâ LLM ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏•‡∏µ‡∏ô data ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ OCR   ‡πÇ‡∏î‡∏¢‡πÄ‡πÄ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô chunk"
      ],
      "metadata": {
        "id": "-zRBq_PR5mT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "# ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå\n",
        "with open(\"/content/drive/MyDrive/LockLearn/combined_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    ocr_text = f.read()\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\n",
        "def chunk_text(text, max_length=2000):\n",
        "    return [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
        "\n",
        "# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° OCR ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏™‡πà‡∏ß‡∏ô\n",
        "chunks = chunk_text(ocr_text)\n",
        "\n",
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î header ‡πÅ‡∏•‡∏∞ API Key ‡∏Ç‡∏≠‡∏á Groq\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer xxxxxxxxxxxx\"  # ‡πÉ‡∏™‡πà Api‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏ô‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö  ‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏ö Bearer ‡∏≠‡∏≠‡∏Å\n",
        "}\n",
        "\n",
        "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "all_cleaned_text = \"\"\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô retry ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î\n",
        "def request_with_retry(json_data, retries=3, delay=5):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.post(\"https://api.groq.com/openai/v1/chat/completions\", headers=headers, json=json_data, timeout=30)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "            elif response.status_code == 429:\n",
        "                print(f\"‚ùå Rate limit reached, retrying after delay...\")\n",
        "                time.sleep(61)  # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ 61 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á Rate Limit\n",
        "            else:\n",
        "                print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API: {response.status_code}\")\n",
        "                print(\"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:\", response.text)\n",
        "                time.sleep(delay)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API: {e}\")\n",
        "            time.sleep(delay)\n",
        "\n",
        "    return None  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ None\n",
        "\n",
        "# ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏ó‡∏µ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô\n",
        "for i, chunk in enumerate(chunks):\n",
        "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ LLaMA 4 Scout ‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "    prompt = f\"\"\"\n",
        "    Please clean and format the following OCR text:\n",
        "    - Correct spelling errors.\n",
        "    - Rearrange sentences to ensure proper structure.\n",
        "    - Remove any non-sentence artifacts or unnecessary lines.\n",
        "    - Retain and format key headings and important sections only.\n",
        "    - Ensure the meaning remains unchanged and the text is easy to read.\n",
        "\n",
        "    OCR Text:\n",
        "    {chunk}\n",
        "    \"\"\"\n",
        "\n",
        "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á payload ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Groq API\n",
        "    json_data = {\n",
        "        \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô API ‡∏î‡πâ‡∏ß‡∏¢‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô retry\n",
        "    result = request_with_retry(json_data)\n",
        "\n",
        "    if result:\n",
        "        all_cleaned_text += result + \"\\n\\n\"  # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏∏‡∏Å‡∏™‡πà‡∏ß‡∏ô\n",
        "        print(f\"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà {i} ‡∏ñ‡∏π‡∏Å‡∏Ñ‡∏•‡∏µ‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡πâ‡∏ß!\")\n",
        "    else:\n",
        "        print(f\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏µ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà {i} ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏•‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á\")\n",
        "\n",
        "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Ñ‡∏•‡∏µ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
        "with open(\"/content/drive/MyDrive/LockLearn/cleaned_text_all.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(all_cleaned_text)\n",
        "\n",
        "print(\"‚úÖ ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!\")\n"
      ],
      "metadata": {
        "id": "oGBWGZrn5zgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏ä‡πâ LLM ( Llama 4 scout) ‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏•‡∏µ‡∏ô‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡πÄ‡πÄ‡∏ï‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏•‡∏µ‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ñ‡∏≥‡πÄ‡πÄ‡∏ô‡∏∞‡∏ô‡∏≥"
      ],
      "metadata": {
        "id": "Sz-J4ef06Ucz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ API Groq ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£ Retry\n",
        "def request_with_retry(json_data, retries=3, delay=5):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer 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\"  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
        "    }\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.post(\"https://api.groq.com/openai/v1/chat/completions\", headers=headers, json=json_data, timeout=30)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "            elif response.status_code == 429:\n",
        "                print(f\"‚ùå Rate limit reached, retrying after delay...\")\n",
        "                time.sleep(61)  # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ 61 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
        "            else:\n",
        "                print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API: {response.status_code}\")\n",
        "                print(\"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:\", response.text)\n",
        "                time.sleep(delay)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API: {e}\")\n",
        "            time.sleep(delay)\n",
        "\n",
        "    return None  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ None\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏±‡∏ô\n",
        "def chunk_text(text, max_length=2000):\n",
        "    \"\"\" ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏±‡∏ô \"\"\"\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in text.split('. '):  # ‡πÉ‡∏ä‡πâ . ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ\n",
        "        if len(current_chunk) + len(sentence) + 2 <= max_length:\n",
        "            current_chunk += sentence + \". \"\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \". \"\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° OCR ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Google Drive\n",
        "file_path = '/content/drive/MyDrive/LockLearn/cleaned_text_all.txt'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    ocr_text = f.read()\n",
        "\n",
        "# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° OCR ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ\n",
        "chunks = chunk_text(ocr_text)\n",
        "\n",
        "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡∏µ‡∏ô‡πÅ‡∏•‡πâ‡∏ß\n",
        "all_cleaned_recommendations = \"\"\n",
        "\n",
        "# ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÉ‡∏´‡πâ LLaMA 4 Scout ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞\n",
        "for i, chunk in enumerate(chunks):\n",
        "    # ‡∏õ‡∏£‡∏±‡∏ö prompt ‡πÉ‡∏´‡πâ LLaMA 4 Scout ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó\n",
        "    prompt = f\"\"\"\n",
        "    Extract all kinds of recommendations or advice from the following text.\n",
        "\n",
        "    Each recommendation should be on a separate line, and there should be a blank line between each recommendation.\n",
        "    The recommendations could involve any aspects of life including personal development, motivation, problem-solving, work-related advice, health tips, financial advice, and more.\n",
        "\n",
        "    OCR Text:\n",
        "    {chunk}\n",
        "    \"\"\"\n",
        "\n",
        "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á JSON payload ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö API\n",
        "    json_data = {\n",
        "        \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡∏µ‡∏ô\n",
        "    result = request_with_retry(json_data)\n",
        "\n",
        "    if result:\n",
        "        all_cleaned_recommendations += result + \"\\n\\n\"  # ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡∏µ‡∏ô‡πÅ‡∏•‡πâ‡∏ß\n",
        "        print(f\"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà {i} ‡∏ñ‡∏π‡∏Å‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÅ‡∏•‡πâ‡∏ß!\")\n",
        "    else:\n",
        "        print(f\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà {i} ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏•‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á\")\n",
        "\n",
        "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Ñ‡∏•‡∏µ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå\n",
        "output_file_path = '/content/drive/MyDrive/LockLearn/cleaned_recommendations.txt'\n",
        "\n",
        "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(all_cleaned_recommendations)\n",
        "\n",
        "print(\"‚úÖ ‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!\")\n"
      ],
      "metadata": {
        "id": "EujMBwTW6ckz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏´‡πâ Llama 4 scout ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡πÄ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡πÄ‡πÄ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏°‡∏≤"
      ],
      "metadata": {
        "id": "xZkHQ5uK7SF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import json\n",
        "\n",
        "# üîë API Key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Together\n",
        "api_key = \"tgp_v1_YuXEZE7brZebc5_LLb-N3sWc3zrOvEHh5O0nx8zHzSE \"  # üëà ‡πÉ‡∏™‡πà Together API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ\n",
        "\n",
        "# ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå\n",
        "total_recommendations = 0\n",
        "received_recommendations = 0\n",
        "\n",
        "# üîÅ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡∏û‡∏£‡πâ‡∏≠‡∏° Retry\n",
        "def request_with_retry(json_data, retries=3, delay=5):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.post(\"https://api.together.xyz/v1/chat/completions\", headers=headers, json=json_data, timeout=30)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "            elif response.status_code in [429, 503]:\n",
        "                print(f\"‚ùå Error {response.status_code}: Retrying after delay...\")\n",
        "                time.sleep(60 if response.status_code == 429 else 30)\n",
        "            else:\n",
        "                print(f\"‚ùå Error (Status {response.status_code})\")\n",
        "                print(\"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:\", response.text)\n",
        "                time.sleep(delay)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"‚ùå Connection Error: {e}\")\n",
        "            time.sleep(delay)\n",
        "\n",
        "    return None\n",
        "\n",
        "# üìÇ ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\n",
        "def read_recommendations(file_path):\n",
        "    global total_recommendations\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        recommendations = f.read().strip().split('\\n\\n')\n",
        "    total_recommendations = len(recommendations)\n",
        "    return [rec.strip() for rec in recommendations if rec.strip()]\n",
        "\n",
        "# üß† ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÅ‡∏ö‡∏ö Batch ‡∏•‡∏∞ 15 ‡∏≠‡∏±‡∏ô\n",
        "def analyze_categories(recommendations, batch_size=15):\n",
        "    global received_recommendations\n",
        "\n",
        "    categorized_recommendations = []\n",
        "    batch_num = 1\n",
        "\n",
        "    while recommendations:\n",
        "        batch = recommendations[:batch_size]\n",
        "        recommendations = recommendations[batch_size:]\n",
        "        joined_recs = \"\\n\".join([f\"- {rec}\" for rec in batch])\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Classify each of the following recommendations individually into the most appropriate category.\n",
        "Possible categories include: Health, Finance, Productivity, Motivation, Mental Health, Lifestyle, Creativity,\n",
        "Self-improvement, Career Development, Relationships, Learning & Education, Time Management, Social Impact.\n",
        "\n",
        "Recommendations:\n",
        "{joined_recs}\n",
        "\n",
        "Please return only the list in the following format:\n",
        "[\n",
        "  {{ \"text\": \"Recommendation\", \"category\": \"Category\" }},\n",
        "  ...\n",
        "]\n",
        "Do not include any additional text or explanations.\n",
        "\"\"\"\n",
        "\n",
        "        json_data = {\n",
        "            \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "        }\n",
        "\n",
        "        result = request_with_retry(json_data)\n",
        "\n",
        "        if result:\n",
        "            try:\n",
        "                batch_results = json.loads(result)\n",
        "                categorized_recommendations.extend(batch_results)\n",
        "                received_recommendations += len(batch_results)\n",
        "                print(f\"‚úÖ Batch {batch_num} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ({len(batch_results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)\")\n",
        "                batch_num += 1\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå JSON ‡πÑ‡∏î‡πâ:\", result)\n",
        "        else:\n",
        "            print(f\"‚ùå ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà Batch ‡∏ó‡∏µ‡πà {batch_num}\")\n",
        "\n",
        "        time.sleep(10)\n",
        "\n",
        "    return categorized_recommendations\n",
        "\n",
        "# üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON\n",
        "def save_to_json(data, output_file_path):\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# üöÄ Main\n",
        "file_path = '/content/drive/MyDrive/LockLearn/cleaned_recommendations.txt'\n",
        "output_file_path = '/content/drive/MyDrive/LockLearn/recommendations_with_categories.json'\n",
        "\n",
        "recs = read_recommendations(file_path)\n",
        "categorized = analyze_categories(recs, batch_size=15)\n",
        "save_to_json(categorized, output_file_path)\n",
        "\n",
        "# üìä ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•\n",
        "data_lost = total_recommendations - received_recommendations\n",
        "print(f\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {total_recommendations} ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\")\n",
        "print(f\"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö {received_recommendations} ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\")\n",
        "print(f\"‚ùå ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ {data_lost} ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\")\n"
      ],
      "metadata": {
        "id": "KeRPmqCo8dIM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}