{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸\n",
        "à¹€à¸›à¹‡à¸™à¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡à¹€à¸à¸·à¹ˆà¸­à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸‚à¸­à¸‡ Embedding model\n",
        "\n",
        "*   à¹‚à¸”à¸¢à¸ˆà¸°à¹ƒà¸Šà¹‰ à¹‚à¸¡à¹€à¸”à¸¥ intfloat/multilingual-e5-large-instruc\n",
        "\n",
        "*   à¸ˆà¸°à¹€à¸™à¹‰à¸™à¸„à¹ˆà¸² Recall@ k   à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\n",
        "\n",
        "\n",
        "\n",
        "à¸„à¸³à¹€à¹€à¸™à¸°à¸™à¸³\n",
        "  à¹ƒà¸«à¹‰à¸—à¸³à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡ google drive à¸à¹ˆà¸­à¸™à¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡\n"
      ],
      "metadata": {
        "id": "fr3ShNjgPO_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oXpCKVWROvrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3c8894-2ae3-4ea4-dc6f-c0591b13abcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "à¹‚à¸«à¸¥à¸”à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™"
      ],
      "metadata": {
        "id": "9ARzdOOUQNVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "9yT-NRHVP6Xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333814fe-258d-4801-8ea7-94a36e3f72f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.59)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.42)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ PyTorch à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™à¸¥à¹ˆà¸²à¸ªà¸¸à¸”\n",
        "!pip install torch==2.0.1"
      ],
      "metadata": {
        "id": "W978UZ4FQKad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539b5b17-6ba3-4c57-a246-2db1a9aa88e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.9.0.58)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: nvidia-nvtx-cu11\n",
            "    Found existing installation: nvidia-nvtx-cu11 11.8.86\n",
            "    Uninstalling nvidia-nvtx-cu11-11.8.86:\n",
            "      Successfully uninstalled nvidia-nvtx-cu11-11.8.86\n",
            "  Attempting uninstall: nvidia-nccl-cu11\n",
            "    Found existing installation: nvidia-nccl-cu11 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu11-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu11-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu11\n",
            "    Found existing installation: nvidia-cusparse-cu11 11.7.5.86\n",
            "    Uninstalling nvidia-cusparse-cu11-11.7.5.86:\n",
            "      Successfully uninstalled nvidia-cusparse-cu11-11.7.5.86\n",
            "  Attempting uninstall: nvidia-curand-cu11\n",
            "    Found existing installation: nvidia-curand-cu11 10.3.0.86\n",
            "    Uninstalling nvidia-curand-cu11-10.3.0.86:\n",
            "      Successfully uninstalled nvidia-curand-cu11-10.3.0.86\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu11\n",
            "    Found existing installation: nvidia-cuda-runtime-cu11 11.8.89\n",
            "    Uninstalling nvidia-cuda-runtime-cu11-11.8.89:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu11-11.8.89\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu11\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu11 11.8.89\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu11-11.8.89:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu11-11.8.89\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu11\n",
            "    Found existing installation: nvidia-cuda-cupti-cu11 11.8.87\n",
            "    Uninstalling nvidia-cuda-cupti-cu11-11.8.87:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu11-11.8.87\n",
            "  Attempting uninstall: nvidia-cublas-cu11\n",
            "    Found existing installation: nvidia-cublas-cu11 11.11.3.6\n",
            "    Uninstalling nvidia-cublas-cu11-11.11.3.6:\n",
            "      Successfully uninstalled nvidia-cublas-cu11-11.11.3.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu11\n",
            "    Found existing installation: nvidia-cusolver-cu11 11.4.1.48\n",
            "    Uninstalling nvidia-cusolver-cu11-11.4.1.48:\n",
            "      Successfully uninstalled nvidia-cusolver-cu11-11.4.1.48\n",
            "  Attempting uninstall: nvidia-cudnn-cu11\n",
            "    Found existing installation: nvidia-cudnn-cu11 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu11-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu11-9.1.0.70\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.3.0\n",
            "    Uninstalling triton-3.3.0:\n",
            "      Successfully uninstalled triton-3.3.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.7.0+cu118\n",
            "    Uninstalling torch-2.7.0+cu118:\n",
            "      Successfully uninstalled torch-2.7.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.7.0+cu118 requires torch==2.7.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.22.0+cu118 requires torch==2.7.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸš€ à¸¥à¸š PyTorch à¹à¸¥à¸° Transformers à¹€à¸à¹ˆà¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "!pip uninstall -y torch torchvision torchaudio transformers\n",
        "\n",
        "# ğŸš€ à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ PyTorch à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š CUDA à¸‚à¸­à¸‡ Colab (CUDA 11.8)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# ğŸš€ à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Transformers à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š\n",
        "!pip install transformers --upgrade"
      ],
      "metadata": {
        "id": "ztEphhzAQMWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a19bea-36b7-44ad-bca4-eb349060b6b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Found existing installation: transformers 4.51.3\n",
            "Uninstalling transformers-4.51.3:\n",
            "  Successfully uninstalled transformers-4.51.3\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.3.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (955.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m955.6/955.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, which is not installed.\n",
            "peft 0.15.2 requires transformers, which is not installed.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 sympy-1.13.3 torch-2.7.0+cu118 torchaudio-2.7.0+cu118 torchvision-0.22.0+cu118 triton-3.3.0\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "Successfully installed transformers-4.51.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain transformers chromadb requests\n",
        "!pip install -q langchain chromadb requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMRJ8b6EPGkF",
        "outputId": "c8df3585-143f-4446-c7e1-56762282d8d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "à¸—à¸³à¸à¸²à¸£ embed à¸„à¸³à¸–à¸²à¸¡à¸‚à¸­à¸‡ Evaluation datasest à¸”à¹‰à¸§à¸¢ intfloat/multilingual-e5-large-instruct"
      ],
      "metadata": {
        "id": "BOgmBsU7QTqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# ğŸš€ à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¹à¸¥à¸° Tokenizer (Hugging Face)\n",
        "model_name = \"intfloat/multilingual-e5-large-instruct\"  # à¹ƒà¸Šà¹‰à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸šà¸—à¸µà¹ˆà¹€à¸à¹‡à¸šà¹ƒà¸™ Vector Database\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name, torch_dtype=torch.float16)  # à¹ƒà¸Šà¹‰ Half-Precision à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # à¸•à¸±à¹‰à¸‡à¹€à¸›à¹‡à¸™à¹‚à¸«à¸¡à¸”à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸œà¸¥à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³\n",
        "\n",
        "# ğŸš€ à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸£à¹‰à¸²à¸‡ Embedding à¸‚à¸­à¸‡à¸„à¸³à¸–à¸²à¸¡\n",
        "def embed_text_batch(texts):\n",
        "    inputs = tokenizer(\n",
        "        texts,\n",
        "        return_tensors='pt',\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "    return embeddings\n",
        "\n",
        "# ğŸš€ à¹‚à¸«à¸¥à¸” Evaluation Dataset\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_datasetv2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"âœ… à¹‚à¸«à¸¥à¸” Evaluation Dataset à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸–à¸²à¸¡-à¸„à¸³à¸•à¸­à¸š: {len(evaluation_data)}\")\n",
        "\n",
        "# ğŸš€ à¸ªà¸£à¹‰à¸²à¸‡ Embeddings à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” (Batch)\n",
        "batch_size = 10  # à¹à¸šà¹ˆà¸‡à¹€à¸›à¹‡à¸™ batch à¸¥à¸° 10 à¸„à¸³à¸–à¸²à¸¡\n",
        "all_embeddings = []\n",
        "\n",
        "for i in range(0, len(evaluation_data), batch_size):\n",
        "    batch_questions = [item['question'] for item in evaluation_data[i:i + batch_size]]\n",
        "\n",
        "    batch_embeddings = embed_text_batch(batch_questions)\n",
        "    all_embeddings.extend(batch_embeddings.tolist())\n",
        "\n",
        "    print(f\"âœ… batch à¸—à¸µà¹ˆ {i // batch_size + 1} embed à¹à¸¥à¹‰à¸§\")\n",
        "\n",
        "    # ğŸš€ à¹€à¸„à¸¥à¸µà¸¢à¸£à¹Œ Cache à¸‚à¸­à¸‡ GPU à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸«à¸™à¹ˆà¸§à¸¢à¸„à¸§à¸²à¸¡à¸ˆà¸³\n",
        "    if device == torch.device(\"cuda\"):\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# ğŸš€ à¹€à¸à¸´à¹ˆà¸¡ Embeddings à¸à¸¥à¸±à¸šà¹€à¸‚à¹‰à¸² Evaluation Dataset\n",
        "for i, item in enumerate(evaluation_data):\n",
        "    item['embedding'] = all_embeddings[i]\n",
        "\n",
        "print(\"âœ… à¸ªà¸£à¹‰à¸²à¸‡ Embeddings à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¹ƒà¸™ Evaluation Dataset à¸ªà¸³à¹€à¸£à¹‡à¸ˆ\")\n",
        "\n",
        "# ğŸš€ à¸à¸³à¸«à¸™à¸”à¹€à¸ªà¹‰à¸™à¸—à¸²à¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸à¹„à¸Ÿà¸¥à¹Œ (Google Drive)\n",
        "output_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2.json'\n",
        "\n",
        "# ğŸš€ à¸šà¸±à¸™à¸—à¸¶à¸ Evaluation Dataset à¸à¸£à¹‰à¸­à¸¡ Embeddings à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œ JSON\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(evaluation_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"âœ… à¸šà¸±à¸™à¸—à¸¶à¸ Evaluation Dataset à¸à¸£à¹‰à¸­à¸¡ Embeddings à¸—à¸µà¹ˆ: {output_file}\")\n"
      ],
      "metadata": {
        "id": "yj4oLv_OQTC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "à¹€à¸Šà¸·à¹ˆà¸­à¸¡ vector database"
      ],
      "metadata": {
        "id": "iMQtWvfRQWO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸš€ 2. à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š Chroma Database à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database'  # à¸£à¸°à¸šà¸¸ path à¸‚à¸­à¸‡à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# à¹‚à¸«à¸¥à¸” Collection à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "print(\"âœ… à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š Chroma DB à¸ªà¸³à¹€à¸£à¹‡à¸ˆ\")\n"
      ],
      "metadata": {
        "id": "53ghM_8YQc6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "à¹€à¸Šà¹‡à¸„à¸§à¹ˆà¸²à¸ªà¸²à¸¡à¸²à¸£à¸–à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸”à¹‰à¸¡à¸±à¹‰à¸¢"
      ],
      "metadata": {
        "id": "Qk0sdyQ1QdfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# ğŸš€ à¹‚à¸«à¸¥à¸” Evaluation Dataset à¸à¸£à¹‰à¸­à¸¡ Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"âœ… à¹‚à¸«à¸¥à¸” Evaluation Dataset à¸à¸£à¹‰à¸­à¸¡ Embeddings à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸–à¸²à¸¡-à¸„à¸³à¸•à¸­à¸š: {len(evaluation_data)}\")\n",
        "\n",
        "# ğŸš€ à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# ğŸš€ à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ RAG à¸”à¸¶à¸‡à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡\n",
        "def retrieve_recommendations(question_embedding, top_k=3):\n",
        "    results = collection.query(\n",
        "        query_embeddings=[question_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "    if results['documents']:\n",
        "        return results['documents'][0]\n",
        "    return []\n",
        "\n",
        "print(\"âœ… à¸à¸£à¹‰à¸­à¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸”à¹‰à¸§à¸¢ RAG\")\n",
        "\n",
        "# ğŸš€ à¸—à¸”à¸¥à¸­à¸‡à¸”à¸¶à¸‡à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¹à¸£à¸\n",
        "test_question = evaluation_data[0]['question']\n",
        "test_embedding = evaluation_data[0]['embedding']\n",
        "\n",
        "recommendations = retrieve_recommendations(test_embedding)\n",
        "print(f\"\\nğŸ” à¸„à¸³à¸–à¸²à¸¡: {test_question}\\nâœ… à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡:\\n\")\n",
        "\n",
        "for idx, rec in enumerate(recommendations, 1):\n",
        "    print(f\"{idx}. {rec}\")\n"
      ],
      "metadata": {
        "id": "YEztfa-vQhaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "à¹ƒà¸«à¹‰à¸„à¹ˆà¸² K = 3"
      ],
      "metadata": {
        "id": "trpTKJIdQlx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# ğŸš€ à¹‚à¸«à¸¥à¸” Evaluation Dataset à¸à¸£à¹‰à¸­à¸¡ Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"âœ… à¹‚à¸«à¸¥à¸” Evaluation Dataset à¸à¸£à¹‰à¸­à¸¡ Embeddings à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸–à¸²à¸¡-à¸„à¸³à¸•à¸­à¸š: {len(evaluation_data)}\")\n",
        "\n",
        "# ğŸš€ à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# ğŸš€ à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ RAG (Retrieve) à¹€à¸à¸·à¹ˆà¸­à¸„à¹‰à¸™à¸«à¸²à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡\n",
        "def retrieve_recommendations(query_embedding, top_k=3):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# ğŸš€ à¹ƒà¸Šà¹‰ RAG à¸„à¹‰à¸™à¸«à¸²à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸à¸„à¸³à¸–à¸²à¸¡à¹ƒà¸™ Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"ğŸ”„ à¸à¸³à¸¥à¸±à¸‡à¸”à¸¶à¸‡à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸”à¹‰à¸§à¸¢ RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=3)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item['category'],\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"âœ… à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸¥à¹‰à¸§ {idx}/{len(evaluation_data)} à¸„à¸³à¸–à¸²à¸¡\")\n",
        "\n",
        "# ğŸš€ à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_K=3.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'âœ… à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ RAG à¸—à¸µà¹ˆ: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "YmJbh96-QW2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "à¸«à¸²à¸„à¹ˆà¸² Recall"
      ],
      "metadata": {
        "id": "thtf_YDZQrE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ evaluation dataset (à¸„à¸³à¸–à¸²à¸¡-à¸„à¸³à¸•à¸­à¸šà¸ˆà¸£à¸´à¸‡)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_datasetv2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ RAG (à¸„à¸³à¸–à¸²à¸¡ + à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¸¡à¸²)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_K=3.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 3  # à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¸¡à¸² (top_k)\n",
        "\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    # à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸™à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ relevant à¸à¸±à¸š retrieved (à¸ˆà¸³à¸à¸±à¸”à¸—à¸µà¹ˆ k à¸•à¸±à¸§à¹à¸£à¸)\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / k\n",
        "\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    # à¸™à¸±à¸šà¸„à¸³à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸™à¹ƒà¸™ top_k / à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸ˆà¸£à¸´à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    # à¸«à¸²à¸¥à¸³à¸”à¸±à¸šà¹à¸£à¸à¸—à¸µà¹ˆà¸„à¸³à¸•à¸­à¸šà¸ˆà¸£à¸´à¸‡à¸›à¸£à¸²à¸à¸à¹ƒà¸™ retrieved\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# à¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸„à¸³à¸™à¸§à¸“à¸•à¹ˆà¸²à¸‡à¹†\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "for item in rag_results:\n",
        "    # à¸„à¸³à¸•à¸­à¸šà¸ˆà¸£à¸´à¸‡ (à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸š list à¹€à¸à¸·à¹ˆà¸­à¸£à¸­à¸‡à¸£à¸±à¸šà¸«à¸¥à¸²à¸¢à¸„à¸³à¸•à¸­à¸šà¹ƒà¸™à¸­à¸™à¸²à¸„à¸•)\n",
        "    relevant_answers = [item['answer']]\n",
        "\n",
        "    # à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¸¡à¸² (list of strings)\n",
        "    retrieved = item['recommendations']\n",
        "\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "# à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡ Precision, Recall, MRR à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "avg_precision = sum(precisions) / len(precisions)\n",
        "avg_recall = sum(recalls) / len(recalls)\n",
        "avg_mrr = sum(mrrs) / len(mrrs)\n",
        "\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "id": "4wDF8annQslF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ecad2a6-be4d-4b27-9838-9d0ce84d5f10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@3: 0.139\n",
            "Recall@3: 0.416\n",
            "Mean Reciprocal Rank (MRR): 0.345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "à¹ƒà¸«à¹‰à¸„à¹ˆà¸² K = 5"
      ],
      "metadata": {
        "id": "vrfKGpKeRSS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# ğŸš€ à¹‚à¸«à¸¥à¸” Evaluation Dataset à¸à¸£à¹‰à¸­à¸¡ Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"âœ… à¹‚à¸«à¸¥à¸” Evaluation Dataset à¸à¸£à¹‰à¸­à¸¡ Embeddings à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸–à¸²à¸¡-à¸„à¸³à¸•à¸­à¸š: {len(evaluation_data)}\")\n",
        "\n",
        "# ğŸš€ à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# ğŸš€ à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ RAG (Retrieve) à¹€à¸à¸·à¹ˆà¸­à¸„à¹‰à¸™à¸«à¸²à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡\n",
        "def retrieve_recommendations(query_embedding, top_k=5):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# ğŸš€ à¹ƒà¸Šà¹‰ RAG à¸„à¹‰à¸™à¸«à¸²à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸à¸„à¸³à¸–à¸²à¸¡à¹ƒà¸™ Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"ğŸ”„ à¸à¸³à¸¥à¸±à¸‡à¸”à¸¶à¸‡à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸”à¹‰à¸§à¸¢ RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=5)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item['category'],\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"âœ… à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸¥à¹‰à¸§ {idx}/{len(evaluation_data)} à¸„à¸³à¸–à¸²à¸¡\")\n",
        "\n",
        "# ğŸš€ à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_K=5.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'âœ… à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ RAG à¸—à¸µà¹ˆ: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "-u8P7HjRRTt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "à¸«à¸²à¸„à¹ˆà¸² Recall"
      ],
      "metadata": {
        "id": "nO4V0f81Rjml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ evaluation dataset (à¸„à¸³à¸–à¸²à¸¡-à¸„à¸³à¸•à¸­à¸šà¸ˆà¸£à¸´à¸‡)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_datasetv2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ RAG (à¸„à¸³à¸–à¸²à¸¡ + à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¸¡à¸²)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_K=5.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 5  # à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¸¡à¸² (top_k)\n",
        "\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    # à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸™à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ relevant à¸à¸±à¸š retrieved (à¸ˆà¸³à¸à¸±à¸”à¸—à¸µà¹ˆ k à¸•à¸±à¸§à¹à¸£à¸)\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / k\n",
        "\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    # à¸™à¸±à¸šà¸„à¸³à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸™à¹ƒà¸™ top_k / à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸ˆà¸£à¸´à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    # à¸«à¸²à¸¥à¸³à¸”à¸±à¸šà¹à¸£à¸à¸—à¸µà¹ˆà¸„à¸³à¸•à¸­à¸šà¸ˆà¸£à¸´à¸‡à¸›à¸£à¸²à¸à¸à¹ƒà¸™ retrieved\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# à¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸„à¸³à¸™à¸§à¸“à¸•à¹ˆà¸²à¸‡à¹†\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "for item in rag_results:\n",
        "    # à¸„à¸³à¸•à¸­à¸šà¸ˆà¸£à¸´à¸‡ (à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸š list à¹€à¸à¸·à¹ˆà¸­à¸£à¸­à¸‡à¸£à¸±à¸šà¸«à¸¥à¸²à¸¢à¸„à¸³à¸•à¸­à¸šà¹ƒà¸™à¸­à¸™à¸²à¸„à¸•)\n",
        "    relevant_answers = [item['answer']]\n",
        "\n",
        "    # à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¸¡à¸² (list of strings)\n",
        "    retrieved = item['recommendations']\n",
        "\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "# à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡ Precision, Recall, MRR à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "avg_precision = sum(precisions) / len(precisions)\n",
        "avg_recall = sum(recalls) / len(recalls)\n",
        "avg_mrr = sum(mrrs) / len(mrrs)\n",
        "\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "id": "LwF3M9SgRlOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bac2c2-0f67-46b5-a552-c55baa9d4560"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@5: 0.096\n",
            "Recall@5: 0.480\n",
            "Mean Reciprocal Rank (MRR): 0.360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "à¹ƒà¸«à¹‰à¸„à¹ˆà¸² K = 10"
      ],
      "metadata": {
        "id": "w_78h8GQRnC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# ğŸš€ à¹‚à¸«à¸¥à¸” Evaluation Dataset à¸à¸£à¹‰à¸­à¸¡ Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"âœ… à¹‚à¸«à¸¥à¸” Evaluation Dataset à¸à¸£à¹‰à¸­à¸¡ Embeddings à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸–à¸²à¸¡-à¸„à¸³à¸•à¸­à¸š: {len(evaluation_data)}\")\n",
        "\n",
        "# ğŸš€ à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# ğŸš€ à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ RAG (Retrieve) à¹€à¸à¸·à¹ˆà¸­à¸„à¹‰à¸™à¸«à¸²à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡\n",
        "def retrieve_recommendations(query_embedding, top_k=10):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# ğŸš€ à¹ƒà¸Šà¹‰ RAG à¸„à¹‰à¸™à¸«à¸²à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸à¸„à¸³à¸–à¸²à¸¡à¹ƒà¸™ Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"ğŸ”„ à¸à¸³à¸¥à¸±à¸‡à¸”à¸¶à¸‡à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸”à¹‰à¸§à¸¢ RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=10)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item['category'],\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"âœ… à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸¥à¹‰à¸§ {idx}/{len(evaluation_data)} à¸„à¸³à¸–à¸²à¸¡\")\n",
        "\n",
        "# ğŸš€ à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_K=10.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'âœ… à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ RAG à¸—à¸µà¹ˆ: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "OPzfyq5JRose"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "à¸«à¸²à¸„à¹ˆà¸² Recall"
      ],
      "metadata": {
        "id": "Vza8WlrzRqQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ evaluation dataset (à¸„à¸³à¸–à¸²à¸¡-à¸„à¸³à¸•à¸­à¸šà¸ˆà¸£à¸´à¸‡)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_datasetv2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ RAG (à¸„à¸³à¸–à¸²à¸¡ + à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¸¡à¸²)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_K=10.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 10  # à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¸¡à¸² (top_k)\n",
        "\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    # à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸™à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ relevant à¸à¸±à¸š retrieved (à¸ˆà¸³à¸à¸±à¸”à¸—à¸µà¹ˆ k à¸•à¸±à¸§à¹à¸£à¸)\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / k\n",
        "\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    # à¸™à¸±à¸šà¸„à¸³à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸™à¹ƒà¸™ top_k / à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸ˆà¸£à¸´à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    # à¸«à¸²à¸¥à¸³à¸”à¸±à¸šà¹à¸£à¸à¸—à¸µà¹ˆà¸„à¸³à¸•à¸­à¸šà¸ˆà¸£à¸´à¸‡à¸›à¸£à¸²à¸à¸à¹ƒà¸™ retrieved\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# à¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸„à¸³à¸™à¸§à¸“à¸•à¹ˆà¸²à¸‡à¹†\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "for item in rag_results:\n",
        "    # à¸„à¸³à¸•à¸­à¸šà¸ˆà¸£à¸´à¸‡ (à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸š list à¹€à¸à¸·à¹ˆà¸­à¸£à¸­à¸‡à¸£à¸±à¸šà¸«à¸¥à¸²à¸¢à¸„à¸³à¸•à¸­à¸šà¹ƒà¸™à¸­à¸™à¸²à¸„à¸•)\n",
        "    relevant_answers = [item['answer']]\n",
        "\n",
        "    # à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¸¡à¸² (list of strings)\n",
        "    retrieved = item['recommendations']\n",
        "\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "# à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡ Precision, Recall, MRR à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\n",
        "avg_precision = sum(precisions) / len(precisions)\n",
        "avg_recall = sum(recalls) / len(recalls)\n",
        "avg_mrr = sum(mrrs) / len(mrrs)\n",
        "\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "id": "Ko-Fnp0lRrkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbc77c9-8bfe-444b-bbc1-2b33ac997972"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@10: 0.055\n",
            "Recall@10: 0.550\n",
            "Mean Reciprocal Rank (MRR): 0.369\n"
          ]
        }
      ]
    }
  ]
}