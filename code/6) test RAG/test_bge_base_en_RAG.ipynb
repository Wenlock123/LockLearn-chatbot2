{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yVY9xGKlQ3VX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb9f536-9904-44a0-8545-adfcf78472a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "Ct9ctwLRS65I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import Together\n",
        "import requests\n",
        "import time\n",
        "import json\n"
      ],
      "metadata": {
        "id": "OZNUiWiYS7YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
        "!pip install torch==2.0.1"
      ],
      "metadata": {
        "id": "YdnNVDexS-Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ ‡∏•‡∏ö PyTorch ‡πÅ‡∏•‡∏∞ Transformers ‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "!pip uninstall -y torch torchvision torchaudio transformers\n",
        "\n",
        "# üöÄ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö CUDA ‡∏Ç‡∏≠‡∏á Colab (CUDA 11.8)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# üöÄ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Transformers ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö\n",
        "!pip install transformers --upgrade\n"
      ],
      "metadata": {
        "id": "O9Ig5rcfS_kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE-M3 (BAAI)\n",
        "model_name = \"BAAI/bge-base-en\"  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE-M3\n",
        "model = SentenceTransformer(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á Embedding ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
        "def embed_text_batch(texts):\n",
        "    embeddings = model.encode(\n",
        "        texts,\n",
        "        convert_to_tensor=True,\n",
        "        show_progress_bar=True,\n",
        "        device=device,\n",
        "        batch_size=32  # ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö batch size ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö GPU ‡πÑ‡∏î‡πâ\n",
        "    )\n",
        "    return embeddings.cpu().numpy()\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_datasetv2.json'  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô v3\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (Batch)\n",
        "batch_size = 10  # ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô batch ‡∏•‡∏∞ 10 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
        "all_embeddings = []\n",
        "\n",
        "for i in range(0, len(evaluation_data), batch_size):\n",
        "    batch_questions = [item['question'] for item in evaluation_data[i:i + batch_size]]\n",
        "\n",
        "    batch_embeddings = embed_text_batch(batch_questions)\n",
        "    all_embeddings.extend(batch_embeddings.tolist())\n",
        "\n",
        "    print(f\"‚úÖ batch ‡∏ó‡∏µ‡πà {i // batch_size + 1} embed ‡πÅ‡∏•‡πâ‡∏ß\")\n",
        "\n",
        "    # üöÄ ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå Cache ‡∏Ç‡∏≠‡∏á GPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# üöÄ ‡πÄ‡∏û‡∏¥‡πà‡∏° Embeddings ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ Evaluation Dataset\n",
        "for i, item in enumerate(evaluation_data):\n",
        "    item['embedding'] = all_embeddings[i]\n",
        "\n",
        "print(\"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô Evaluation Dataset ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
        "\n",
        "# üöÄ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå (Google Drive)\n",
        "output_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v3_BGE-M3.json'  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô v3\n",
        "\n",
        "# üöÄ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå JSON\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(evaluation_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏ó‡∏µ‡πà: {output_file}\")\n"
      ],
      "metadata": {
        "id": "RFO6Fu6tRbv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏™‡∏£‡πâ‡∏≤‡∏á vector database"
      ],
      "metadata": {
        "id": "VPRqFPVKSdjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ 2. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma Database ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v3'  # ‡∏£‡∏∞‡∏ö‡∏∏ path ‡∏Ç‡∏≠‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î Collection ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "print(\"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n"
      ],
      "metadata": {
        "id": "ZXUXbeIJR_Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K = 3"
      ],
      "metadata": {
        "id": "sTMss2gRScwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings (‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå v3 BGE-M3)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v3_BGE-M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB (‡πÉ‡∏ä‡πâ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• v3)\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v3'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á\n",
        "def retrieve_recommendations(question_embedding, top_k=3):\n",
        "    results = collection.query(\n",
        "        query_embeddings=[question_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "    if results and 'documents' in results and len(results['documents']) > 0:\n",
        "        return results['documents'][0]\n",
        "    return []\n",
        "\n",
        "print(\"‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏î‡πâ‡∏ß‡∏¢ RAG\")\n",
        "\n",
        "# üöÄ ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏£‡∏Å\n",
        "test_question = evaluation_data[0]['question']\n",
        "test_embedding = evaluation_data[0]['embedding']\n",
        "\n",
        "recommendations = retrieve_recommendations(test_embedding)\n",
        "print(f\"\\nüîé ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {test_question}\\n‚úÖ ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á:\\n\")\n",
        "\n",
        "for idx, rec in enumerate(recommendations, 1):\n",
        "    print(f\"{idx}. {rec}\")\n"
      ],
      "metadata": {
        "id": "kx1wQcaTSKJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå evaluation dataset (‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v3_BGE-M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG (‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° + ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v3_BGE-M3_K=3.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 3  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤ (top_k)\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision@K\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / k if k > 0 else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Recall@K\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Mean Reciprocal Rank (MRR)\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# üöÄ ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡πà‡∏≤‡∏á‡πÜ\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\")\n",
        "\n",
        "for idx, item in enumerate(rag_results, 1):\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "    if 'answer' not in item or 'recommendations' not in item:\n",
        "        print(f\"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {idx} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ...\")\n",
        "        continue\n",
        "\n",
        "    # ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á (‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö list ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï)\n",
        "    relevant_answers = [item['answer']] if isinstance(item['answer'], str) else item['answer']\n",
        "\n",
        "    # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤ (list of strings)\n",
        "    retrieved = item['recommendations']\n",
        "\n",
        "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(rag_results):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(rag_results)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á Precision, Recall, MRR ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "avg_mrr = sum(mrrs) / len(mrrs) if mrrs else 0\n",
        "\n",
        "print(\"\\nüîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG\")\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB57FnKWSZBs",
        "outputId": "6591e0df-cc64-420c-9184-576a0d7cd35b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 400/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 500/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 600/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 700/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 800/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 900/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1000/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1370/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "\n",
            "üîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG\n",
            "Precision@3: 0.001\n",
            "Recall@3: 0.003\n",
            "Mean Reciprocal Rank (MRR): 0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K = 5"
      ],
      "metadata": {
        "id": "-VHdLVIpSgX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v3_BGE-M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v3'  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô Database ‡πÉ‡∏´‡∏°‡πà\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG (Retrieve) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á\n",
        "def retrieve_recommendations(query_embedding, top_k=5):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# üöÄ ‡πÉ‡∏ä‡πâ RAG ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=5)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item['category'],\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(evaluation_data)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v3_BGE-M3_K=5.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG ‡∏ó‡∏µ‡πà: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "V0zdmWkGSifT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå evaluation dataset (‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v3_BGE-M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG (‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° + ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v3_BGE-M3_K=5.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 5  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤ (top_k)\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision@K\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / k if k > 0 else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Recall@K\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Mean Reciprocal Rank (MRR)\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# üöÄ ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡πà‡∏≤‡∏á‡πÜ\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\")\n",
        "\n",
        "for idx, item in enumerate(rag_results, 1):\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "    if 'answer' not in item or 'recommendations' not in item:\n",
        "        print(f\"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {idx} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ...\")\n",
        "        continue\n",
        "\n",
        "    # ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á (‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö list ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï)\n",
        "    relevant_answers = [item['answer']] if isinstance(item['answer'], str) else item['answer']\n",
        "\n",
        "    # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤ (list of strings)\n",
        "    retrieved = item['recommendations']\n",
        "\n",
        "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(rag_results):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(rag_results)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á Precision, Recall, MRR ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "avg_mrr = sum(mrrs) / len(mrrs) if mrrs else 0\n",
        "\n",
        "print(\"\\nüîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG\")\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RzF11uWSl4V",
        "outputId": "2cdd9829-109b-48a0-a207-de57a30ce531"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 400/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 500/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 600/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 700/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 800/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 900/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1000/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1370/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "\n",
            "üîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG\n",
            "Precision@5: 0.001\n",
            "Recall@5: 0.003\n",
            "Mean Reciprocal Rank (MRR): 0.002\n"
          ]
        }
      ]
    }
  ]
}