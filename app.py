import os
import sys
import re
import shutil
import gdown
import zipfile
import streamlit as st
import requests

# --- Patch sqlite3 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Streamlit Cloud ---
__import__('pysqlite3')
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

from chromadb import PersistentClient
from sentence_transformers import SentenceTransformer

# --- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤ Streamlit ---
st.set_page_config(page_title="LockLearn Lifecoach", page_icon="üíñ", layout="centered")

# --- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
folder_path = "./chromadb_database_v2"
zip_file_path = "./chromadb_database_v2.zip"

# --- ‡∏•‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô schema ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô ---
if os.path.exists(folder_path):
    shutil.rmtree(folder_path)

# --- ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå zip vector database ‡∏à‡∏≤‡∏Å Google Drive ---
st.info("üì¶ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (Vector DB) ‡∏à‡∏≤‡∏Å Google Drive...")

# ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ID ‡πÉ‡∏´‡∏°‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
gdrive_file_id = "1czCTZUvq-ooRt6_-YL_hzYTYDuOdmNpB"
gdown.download(id=gdrive_file_id, output=zip_file_path, quiet=False, use_cookies=False)

# ‡πÅ‡∏ï‡∏Å zip ‡πÑ‡∏ü‡∏•‡πå
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(folder_path)

os.remove(zip_file_path)

st.success("‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏ï‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!")

# --- ‡πÇ‡∏´‡∏•‡∏î ChromaDB ‡πÅ‡∏ö‡∏ö persistent client ---
try:
    client = PersistentClient(path=folder_path)
except Exception as e:
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î ChromaDB ‡πÑ‡∏î‡πâ: {e}")
    st.stop()

# --- ‡πÇ‡∏´‡∏•‡∏î collection ---
try:
    collection = client.get_collection(name="recommendations")
except Exception:
    collection = client.create_collection(name="recommendations")

# --- ‡πÇ‡∏´‡∏•‡∏î embedding model ---
embedding_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')

# --- ‡πÇ‡∏´‡∏•‡∏î API Key ---
api_key = st.secrets["TOGETHER_API_KEY"]

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ---
def query_llm_with_chat(prompt, api_key):
    url = "https://api.together.xyz/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": "meta-llama/llama-4-scout-17b-16e-instruct",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "top_p": 0.9,
        "max_tokens": 512,
    }
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=15)
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"].strip()
        else:
            return f"‚ùå API Error {response.status_code}: {response.text}"
    except Exception as e:
        return f"‚ùå Request failed: {e}"

# --- ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å ChromaDB ---
def retrieve_recommendations(question_embedding, top_k=10):
    results = collection.query(query_embeddings=[question_embedding], n_results=top_k)
    return results['documents'][0] if results and results.get('documents') else []

# --- ‡∏ï‡∏£‡∏ß‡∏à closing message ---
def is_closing_message(text):
    patterns = [r"^‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì.*", r"^‡πÇ‡∏≠‡πÄ‡∏Ñ.*", r"^‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à.*", r"^‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏≤‡∏ö.*", r"^thank.*", r"^ok.*", r"^noted.*"]
    return any(re.match(p, text.strip().lower()) for p in patterns if len(text.split()) <= 5)

# --- ‡∏ï‡∏£‡∏ß‡∏à gibberish/typo ---
def is_gibberish_or_typo(text):
    text = text.strip()
    return len(text) <= 2 or (len(text.split()) == 1 and not re.search(r'[a-zA-Z‡∏Å-‡πô]', text))

# --- ‡∏ï‡∏£‡∏ß‡∏à‡∏†‡∏≤‡∏©‡∏≤ ---
def detect_language(text):
    return "th" if len(re.findall(r'[\u0E00-\u0E7F]', text)) / max(len(text), 1) > 0.3 else "en"

# --- Session state ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- UI ---
st.title("üíñ LockLearn Lifecoach")

for entry in st.session_state.chat_history:
    with st.chat_message(entry["role"]):
        st.markdown(entry["content"])

user_input = st.chat_input("How can I support you today?")

if user_input:
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    lang = detect_language(user_input)

    if is_gibberish_or_typo(user_input):
        reply = {"th": "üòÖ ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏≠‡∏∞‡πÑ‡∏£ ‡∏•‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö", "en": "üòÖ I'm not sure what you mean. Could you try rephrasing it?"}[lang]
    elif is_closing_message(user_input):
        reply = {"th": "üòä ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡πÄ‡∏™‡∏°‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö!", "en": "üòä You're always welcome! Feel free to ask if you need more support!"}[lang]
    else:
        with st.spinner("Thinking..."):
            question_embedding = embedding_model.encode(user_input).tolist()
            recommendations = retrieve_recommendations(question_embedding, top_k=10)

            prompt = f"""
User message: "{user_input}"

Step 1: Briefly analyze the user's feelings or situation based on the message above.
Step 2: Using your analysis and the recommendations below, generate a supportive and practical response.

Recommendations:
"""
            for rec in recommendations:
                prompt += f"- {rec}\n"

            prompt += f"""

Please respond in {'Thai' if lang == 'th' else 'English'} with a {'polite and warm tone, ending sentences with "‡∏Ñ‡πà‡∏∞"' if lang == 'th' else 'kind and uplifting tone like a supportive female life coach'}.

Your response should:
- Reflect understanding of the user's feelings or situation.
- Naturally incorporate relevant recommendations.
- Avoid repeating the user's exact words or the recommendations verbatim.
- Be concise (1‚Äì2 sentences) and encouraging.
"""
            reply = query_llm_with_chat(prompt, api_key)

    st.session_state.chat_history.append({"role": "assistant", "content": reply})
    with st.chat_message("assistant", avatar="üßò‚Äç‚ôÄÔ∏è"):
        st.markdown(reply)
