import os
import sys
import re
import shutil
import gdown
import zipfile
import streamlit as st
import requests

# Patch sqlite3 for Streamlit Cloud
__import__('pysqlite3')
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

from chromadb import PersistentClient
from sentence_transformers import SentenceTransformer

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Streamlit
st.set_page_config(page_title="LockLearn Lifecoach", page_icon="üíñ", layout="centered")

# Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
folder_path = "./chromadb_database_v2"
zip_file_path = "./chromadb_database_v2.zip"

# ‡∏•‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤
if os.path.exists(folder_path):
    shutil.rmtree(folder_path)

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå zip ‡∏à‡∏≤‡∏Å Google Drive
st.info("üì¶ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (Vector DB) ‡∏à‡∏≤‡∏Å Google Drive...")
gdrive_file_id = "1czCTZUvq-ooRt6_-YL_hzYTYDuOdmNpB"
gdown.download(id=gdrive_file_id, output=zip_file_path, quiet=False, use_cookies=False)

# ‡πÅ‡∏ï‡∏Å zip
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(folder_path)
os.remove(zip_file_path)

st.success("‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏ï‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!")

# ‡πÇ‡∏´‡∏•‡∏î ChromaDB
try:
    client = PersistentClient(path=folder_path)
    collections = client.list_collections()
    collection_names = [c.name for c in collections]
    if "recommendations" in collection_names:
        collection = client.get_collection(name="recommendations")
    else:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö collection 'recommendations' ‚Äî ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á collection ‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏ó‡∏ô")
        collection = client.create_collection(name="recommendations")
except Exception as e:
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î ChromaDB ‡πÑ‡∏î‡πâ: {e}")
    st.stop()

# ‡πÇ‡∏´‡∏•‡∏î embedding model
try:
    embedding_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2', device='cpu')
    st.info("‚úÖ ‡πÇ‡∏´‡∏•‡∏î embedding model paraphrase-multilingual-mpnet-base-v2 ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß (CPU mode)")
except Exception as e:
    st.error(f"‚ùå ‡πÇ‡∏´‡∏•‡∏î embedding model ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")
    st.stop()

# ‡πÇ‡∏´‡∏•‡∏î API Key
api_key = st.secrets["TOGETHER_API_KEY"]

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM
def query_llm_with_chat(prompt, api_key):
    url = "https://api.together.xyz/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": "meta-llama/llama-4-scout-17b-16e-instruct",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "top_p": 0.9,
        "max_tokens": 512,
    }
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=15)
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"].strip()
        else:
            return f"‚ùå API Error {response.status_code}: {response.text}"
    except Exception as e:
        return f"‚ùå Request failed: {e}"

# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
def retrieve_recommendations(question_embedding, top_k=10):
    results = collection.query(query_embeddings=[question_embedding], n_results=top_k)
    return results['documents'][0] if results and results.get('documents') else []

# ‡∏ï‡∏£‡∏ß‡∏à closing message
def is_closing_message(text):
    patterns = [r"^‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì.*", r"^‡πÇ‡∏≠‡πÄ‡∏Ñ.*", r"^‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à.*", r"^‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏≤‡∏ö.*", r"^thank.*", r"^ok.*", r"^noted.*"]
    return any(re.match(p, text.strip().lower()) for p in patterns if len(text.split()) <= 5)

# ‡∏ï‡∏£‡∏ß‡∏à gibberish/typo
def is_gibberish_or_typo(text):
    text = text.strip()
    return len(text) <= 2 or (len(text.split()) == 1 and not re.search(r'[a-zA-Z‡∏Å-‡πô]', text))

# ‡∏ï‡∏£‡∏ß‡∏à‡∏†‡∏≤‡∏©‡∏≤
def detect_language(text):
    return "th" if len(re.findall(r'[\u0E00-\u0E7F]', text)) / max(len(text), 1) > 0.3 else "en"

# Session state
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# UI
st.title("üíñ LockLearn Lifecoach")

for entry in st.session_state.chat_history:
    with st.chat_message(entry["role"]):
        st.markdown(entry["content"])

user_input = st.chat_input("How can I support you today?")

if user_input:
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    lang = detect_language(user_input)

    if is_gibberish_or_typo(user_input):
        reply = {
            "th": "üòÖ ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏≠‡∏∞‡πÑ‡∏£ ‡∏•‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö",
            "en": "üòÖ I'm not sure what you mean. Could you try rephrasing it?"
        }[lang]
    elif is_closing_message(user_input):
        reply = {
            "th": "üòä ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡πÄ‡∏™‡∏°‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö!",
            "en": "üòä You're always welcome! Feel free to ask if you need more support!"
        }[lang]
    else:
        with st.spinner("Thinking..."):
            try:
                question_embedding = embedding_model.encode(user_input).tolist()
                recommendations = retrieve_recommendations(question_embedding, top_k=10)

                prompt = f"""
User message: "{user_input}"

Step 1: Briefly analyze the user's feelings or situation based on the message above.
Step 2: Using your analysis and the recommendations below, generate a supportive and practical response.

Recommendations:
"""
                for rec in recommendations:
                    prompt += f"- {rec}\n"

                prompt += """
Please generate a supportive, practical, and encouraging response based on the suggestions above.
Respond in the same language as the user's question:
- Thai if the question is in Thai.
- English if the question is in English.

If the user's question is in Thai, respond in a polite and feminine tone using "‡∏Ñ‡πà‡∏∞" at the end of the sentence, as if you are a female life coach giving kind, warm, and caring motivation.
If the user's question is in English, keep a kind and uplifting tone like a supportive female life coach.

Keep the response concise (1‚Äì2 sentences), natural, and motivating.
"""

                reply = query_llm_with_chat(prompt, api_key)
            except Exception as e:
                reply = f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {e}"

    st.session_state.chat_history.append({"role": "assistant", "content": reply})
    with st.chat_message("assistant", avatar="üßò‚Äç‚ôÄÔ∏è"):
        st.markdown(reply)
